#!/usr/bin/env python

# Copyright (C) 2017 Derek Davis and TJ Massinger
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

import numpy as np
import scipy.signal as sig
from argparse import ArgumentParser
import os
import h5py
from pycbc.types import TimeSeries
from pycbc import frame
from datetime import datetime
import logging

from pycbc.filter import crosstalk


ap = ArgumentParser(description='Takes input hdf files copntaining individual'+ 
                ' transfer functions and ouputs a single hdf containing'+
                ' all said transfer functions.')
ap.add_argument('--hdf-tf-file',required=True, nargs='+',
                help='Path to file containing relevant noise timeseries')
ap.add_argument('--output-hdf-file', default='./MERGED-TF-FILE.hdf',
                help='Location of output files')
args = ap.parse_args()

logging.basicConfig(format='%(asctime)s %(message)s', level=logging.INFO)

file_path = args.output_hdf_file

input_file_List = args.hdf_tf_file

start_data = 0
end_data = 1e20

#Read in first hdf, use as base
logging.info('Reading in first file to determine constants')
tf_dict,base_start_list,base_aux_chan_list,base_duration_tf,base_filter_length = crosstalk.read_tf_hdf(input_file_List[0],start_data,end_data)

logging.info("duration tf is {}".format(base_duration_tf))

#Set up new merged hdf file
crosstalk.create_tf_hdf(file_path,base_start_list,base_aux_chan_list,base_duration_tf,base_filter_length)

#Insert first transfer function
assert len(base_start_list) != 0
tf_start = base_start_list[0]
full_tf_list = tf_dict[tf_start]
crosstalk.append_tf_hdf(file_path,tf_start,base_aux_chan_list,full_tf_list)

full_start_list = [tf_start]

logging.info("File initialized, reading in individual transfer functions")

#Read in remaining tfs and add 
#remaining tfs one by one
for hdf_file in input_file_List[1:]:
    tf_dict,start_list,aux_chan_list,duration_tf,filter_length = crosstalk.read_tf_hdf(hdf_file,start_data,end_data)
    for new_chan, base_chan in zip(aux_chan_list,base_aux_chan_list):
        assert new_chan == base_chan
    assert duration_tf == base_duration_tf
    assert filter_length == base_filter_length
    assert len(start_list) != 0
    tf_start = start_list[0]
    full_tf_list = tf_dict[tf_start]
    full_start_list.append(tf_start)
    crosstalk.append_tf_hdf(file_path,tf_start,aux_chan_list,full_tf_list)

print full_start_list

#Override start_list
hdf_file = h5py.File(file_path, 'r+')     
start_key = hdf_file.keys()[0] #need to figure out what this is for ifo designation
start_dataset = hdf_file[start_key+'/times']       
del hdf_file[start_key+'/times']
start_dataset = hdf_file.create_dataset(start_key+'/times', data=full_start_list)      
hdf_file.close()                          

logging.info('Done')
