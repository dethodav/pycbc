#!/usr/bin/env python
import numpy as np
import scipy.signal as sig
from argparse import ArgumentParser
import os
import h5py
from pycbc.types import TimeSeries
from pycbc import frame
from datetime import datetime

from pycbc.filter import asd2

ap = ArgumentParser(description='Takes input transfer functions and cleans h(t) '+
                'data using the relevant aux channel. The cleaned data can then '+
                'be written to disk')
ap.add_argument('--gps-start-time',type=int,required=True,
                help='Start time to calculate the transfer functions. '+
                'Note that there is an initial loss of time due to corruption.')
ap.add_argument('--gps-end-time',type=int,required=True,
                help='End time to calculate the transfer functions. '+
                'Note that there is an final loss of time due to corruption.')
ap.add_argument('--tf-file',required=True,
                help='Path to file containing relevant transfer functions')
ap.add_argument('--ifo',required=True,
                help='IFO')
ap.add_argument('--output-frame-path', default='./NOISE_FRAME.gwf',
                help='Location of output files')
ap.add_argument('--output-frame-channel',
                help='Name of strain channel in output file.')
args = ap.parse_args()

#Input information, passed as arguments
ifo = args.ifo
start_data=args.gps_start_time
end_data=args.gps_end_time
file_size = None

#Read in transfer functions and set up cleaning parameters
tf_dict,start_list,aux_chan_list,duration_tf,filter_length = asd2.read_tf_hdf(args.tf_file,start_data,end_data)
cut = int(np.ceil(0.5*filter_length))
duration_data = end_data - start_data - 2*cut
write_size = np.ceil(float(file_size)/float(duration_tf))

#Set buffer to none 
#Will be added to later
noise_data_buffer = None

print "Removing noise using:"
print aux_chan_list

#Clean each chunk seperately
#will be added together at end
for tf_start in start_list:
    print "Working on data starting at:", tf_start
 
    #sets time for start and end
    st = tf_start
    ed = st + duration_tf
    if (st == start_list[-1]):
        ed = end_data

    #Grab data - This is all based on gwpy reading methods - MAKE AS A FUNCTION - ONLY READ IN NEEDED DATA
    print str(datetime.now()),"  reading data..."
    data, aux_data = asd2.read_in(st,ed,aux_chan_list,cut,ifo,no_strain=True)
    print "data starts out with", data.duration

    #picks out which set of tf to use
    det_tf = tf_dict[tf_start]

    #cleaning that chunk
    print str(datetime.now()),"  cleaning data..."
    data_nojit, noise_subtracted = asd2.clean_data(aux_data[0],aux_data,det_tf)

    #Add data to the buffer, and write out if needed
    print str(datetime.now()),"  adding to buffer..."
    noise_data_buffer = asd2.add_buffer(noise_subtracted, prev_buffer=noise_data_buffer, dur=duration_tf, 
                                  write=True, write_size=file_size)

#Write the remaining data tail to frames
noise_fname = args.output_frame_path
frame.write_frame(noise_fname, '%s:%s' % (ifo, args.output_frame_channel), noise_data_buffer)


